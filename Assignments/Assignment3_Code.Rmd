---
title: "Assignment 3"
subtitle: "Group Assignment 3"
author:
  - "Rishi Ashok Kumar (560527)"
  - "Nicolas Gonzalez (780037)"
  - "Aleksandra Tatko (648925)"
  - "André van der Meij (589994)"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
output:
  pdf_document:
    latex_engine: xelatex
  html_document: default
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup}
# Load required packages
library(tidyverse)
library(factoextra)
library(cluster)
getwd()
# Load dataset
hotel_customers <- read.csv("/Users/nico/Documents/EUR/Marketing/Assignment/Strategic-Marketing/Assignments/HotelCustomersSubset_sample.csv")

# Quick look at the data
str(hotel_customers)
head(hotel_customers)
summary(hotel_customers)

# Set seed
set.seed(123)
```

```{r cleaning}
# Convert Age to integer
hotel_customers$Age <- as.numeric(hotel_customers$Age)

# Remove missing and unrealistic age values
hotel_customers <- hotel_customers %>%
  filter(!is.na(Age) & Age >= 18 & Age <= 95)
```

```{r include=FALSE}
# Select the variables
selected_variables <- c(
  "Age","AverageLeadTime","DaysSinceCreation",
  "LodgingRevenue","OtherRevenue",
  "PersonsNights","RoomNights",
  "DaysSinceLastStay","DaysSinceFirstStay"
)

# Keep columns of selected variables and check for missing values 
analysis_data <- hotel_customers %>%
  select(all_of(selected_variables)) %>%
  drop_na()
```

```{r scale, include=FALSE}
# Standardize all variables
analysis_data_scaled <- scale(analysis_data)
```

```{r scale1, include=FALSE}
# Standardize all variables
analysis_data_scaled <- scale(analysis_data)
```

```{r optimalk,  include=FALSE}
# Check with elbow method
fviz_nbclust(analysis_data_scaled, kmeans, method = "wss", k.max = 13) 

# Check with silhouette method
fviz_nbclust(analysis_data_scaled, kmeans, method = "silhouette", k.max = 13) 
```

So in both cases k seems to be the optimal number of cluster
Elbow method: the curve starts to flatten after k = 4
Silhouette method: highest average silhouette width at k = 4

```{r kmeans , include=FALSE}
# Perform k
kmeans_result <- kmeans(analysis_data_scaled, centers = 4, nstart = 25)

# Add cluster to original data set
hotel_customers$Cluster <- as.factor(kmeans_result$cluster)
```

- centers = 4, the found in Q1
- nstart = 25, → runs the algorithm 25 times with different starting points, after it keeps the best result -> this reduces the chance of getting stuck in a local minimum, as mentioned in Lecture 6 (slide 43)

```{r plotclustersizes, include=FALSE}
# Create data frame
cluster_sizes <- data.frame(
  Cluster = factor(1:4),
  Size = kmeans_result$size
)

# Plot cluster sizes
p3 <- ggplot(cluster_sizes, aes(x = Cluster, y = Size, fill = Cluster)) +
  geom_col(show.legend = FALSE) +
  labs(
    title = "Cluster Sizes",
    x = "Cluster",
    y = "Number of Customers"
  ) +
  theme_minimal()
print(p3)
```

```{r plotsegmentationsolution , include=FALSE}
# Visualize the 4-cluster segmentation solution
fviz_cluster(kmeans_result, data = analysis_data_scaled,
             ellipse.type = "norm",
             geom = "point",
             palette = "Set2",
             main = "K-Means Segmentation Solution") +
  theme_minimal(base_size = 13)
```
```{r plotsegmentationsolution1, include=FALSE}
# Compute the mean of each variable per cluster
cluster_profile <- hotel_customers %>%
  group_by(Cluster) %>%
  summarise(
    Age = mean(Age, na.rm = TRUE),
    AverageLeadTime = mean(AverageLeadTime, na.rm = TRUE),
    DaysSinceCreation = mean(DaysSinceCreation, na.rm = TRUE),
    LodgingRevenue = mean(LodgingRevenue, na.rm = TRUE),
    OtherRevenue = mean(OtherRevenue, na.rm = TRUE),
    PersonsNights = mean(PersonsNights, na.rm = TRUE),
    RoomNights = mean(RoomNights, na.rm = TRUE),
    DaysSinceLastStay = mean(DaysSinceLastStay, na.rm = TRUE),
    DaysSinceFirstStay = mean(DaysSinceFirstStay, na.rm = TRUE)
  ) %>%
  pivot_longer(-Cluster, names_to = "Variable", values_to = "Average")

# Bar plot of average variable values per cluster
ggplot(cluster_profile, aes(x = Variable, y = Average, fill = Cluster)) +
  geom_col(position = "dodge") +
  labs(
    title = "Overall Segmentation Solution by Mean",
    x = "Variable",
    y = "Average Value"
  ) +
  theme_minimal(base_size = 12) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r lodgingrevenue, include=FALSE}
# Compute average and total revenues per cluster
lodging_plot <- hotel_customers %>%
  group_by(Cluster) %>%
  summarise(avg_lodgingrevenue = mean(LodgingRevenue, na.rm = TRUE)) %>%
  ggplot(aes(x = Cluster, y = avg_lodgingrevenue, fill = Cluster)) +
  geom_col(show.legend = FALSE) +
  geom_text(aes(label = round(avg_lodgingrevenue, 0)), vjust = -0.5) +
  labs(
    title = "Average Lodging Revenue per Customer by Cluster",
    x = "Cluster",
    y = "Average Lodging Revenue (€)"
  ) +
  theme_minimal(base_size = 13)

lodging_plot
```

```{r otherrevenue include=FALSE}
other_plot <- hotel_customers %>%
  group_by(Cluster) %>%
  summarise(avg_otherrevenue = mean(OtherRevenue, na.rm = TRUE)) %>%
  ggplot(aes(x = Cluster, y = avg_otherRevenue, fill = Cluster)) +
  geom_col(show.legend = FALSE) +
  geom_text(aes(label = round(avg_otherRevenue, 0)), vjust = -0.5) +
  labs(
    title = "Average Other Revenue per Customer by Cluster",
    x = "Cluster",
    y = "Average Other Revenue (€)"
  ) +
  theme_minimal(base_size = 13)

other_plot
```
